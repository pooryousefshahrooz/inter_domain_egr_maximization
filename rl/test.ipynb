{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf\n",
    "from env import Environment\n",
    "from game import CFRRL_Game\n",
    "from model import Model\n",
    "from network import Network\n",
    "from config import get_config\n",
    "from solver import Solver\n",
    "import csv\n",
    "import time\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('ckpt', '', 'apply a specific checkpoint')\n",
    "flags.DEFINE_boolean('eval_delay', False, 'evaluate delay or not')\n",
    "\n",
    "def sim(config, model,network,solver, game,tm_idx):\n",
    "    #for tm_idx in game.tm_indexes:\n",
    "    state = game.get_state(tm_idx)\n",
    "    if config.method == 'actor_critic':\n",
    "        policy = model.actor_predict(np.expand_dims(state, 0)).numpy()[0]\n",
    "    elif config.method == 'pure_policy':\n",
    "        policy = model.policy_predict(np.expand_dims(state, 0)).numpy()[0]\n",
    "    actions = policy.argsort()[-game.max_moves:]\n",
    "\n",
    "    egr = game.evaluate(tm_idx,network,solver,\"RL\",actions) \n",
    "    return egr\n",
    "def main(_):\n",
    "    #Using cpu for testing\n",
    "    tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "    tf.get_logger().setLevel('INFO')\n",
    "\n",
    "    config = get_config(FLAGS) or FLAGS\n",
    " \n",
    "    \n",
    "    \n",
    "    solver = Solver()\n",
    "    for num_paths in range(int(config.min_num_of_paths),int(config.num_of_paths)+1):\n",
    "        for network_topology in config.topology_file:\n",
    "            for edge_capacity_bound in config.edge_capacity_bounds:\n",
    "                network = Network(config,edge_capacity_bound,True)\n",
    "                for fidelity_threshold_up_range in config.fidelity_threshold_ranges:\n",
    "                    network.fidelity_threshold_range = fidelity_threshold_up_range\n",
    "                    network.set_each_wk_k_fidelity_threshold()\n",
    "                    for edge_fidelity_range in config.edge_fidelity_ranges:\n",
    "                        network.end_level_purification_flag = True\n",
    "                        network.set_edge_fidelity(edge_fidelity_range)\n",
    "                        # we get all the paths for all workloads\n",
    "                        network.num_of_paths = num_paths\n",
    "                        network.get_path_info()\n",
    "                        each_wk_scheme_egr ={}\n",
    "                        each_wk_idx_optimal = {}\n",
    "                        \"\"\"we first find the candidate paths and use it for action dimention\"\"\"\n",
    "                        # we se the state dimention and action dimention\n",
    "\n",
    "\n",
    "                        game = CFRRL_Game(config, network)\n",
    "                        model = Model(config, game.state_dims, game.action_dim, game.max_moves)\n",
    "                        last_chckpoint = model.restore_ckpt(FLAGS.ckpt)\n",
    "                        while(last_chckpoint <=config.max_step):\n",
    "                            time.sleep(1)\n",
    "                            model = Model(config, game.state_dims, game.action_dim, game.max_moves)\n",
    "                            current_chckpoint = model.restore_ckpt(FLAGS.ckpt)\n",
    "                            if config.method == 'actor_critic':\n",
    "                                learning_rate = model.lr_schedule(model.actor_optimizer.iterations.numpy()).numpy()\n",
    "                            elif config.method == 'pure_policy':\n",
    "                                learning_rate = model.lr_schedule(model.optimizer.iterations.numpy()).numpy()\n",
    "                            print('\\nstep %d, learning rate: %f\\n'% (current_chckpoint, learning_rate))\n",
    "                            if last_chckpoint<current_chckpoint:\n",
    "                                last_chckpoint = current_chckpoint\n",
    "                                for wk_idx in range(len(game.wk_indexes)):\n",
    "                                    try:\n",
    "                                        if wk_idx in each_wk_scheme_egr:\n",
    "                                            EGR_egr = each_wk_scheme_egr[wk_idx][\"EGR\"]\n",
    "                                            hop_egr = each_wk_scheme_egr[wk_idx][\"hop\"]\n",
    "                                            EGRSQUARE_egr = each_wk_scheme_egr[wk_idx][\"EGRsquare\"]\n",
    "                                            optimal_egr = each_wk_scheme_egr[wk_idx][\"Optimal\"]\n",
    "\n",
    "                                        else:\n",
    "                                            EGR_egr = game.evaluate(wk_idx,network,solver,\"EGR\",[])\n",
    "                                            hop_egr = game.evaluate(wk_idx,network,solver,\"hop\",[])\n",
    "                                            EGRSQUARE_egr = game.evaluate(wk_idx,network,solver,\"EGRsquare\",[])\n",
    "                                            optimal_egr = game.evaluate(wk_idx,network,solver,\"Optimal\",[])\n",
    "                                            try:\n",
    "                                                each_wk_scheme_egr[wk_idx][\"EGR\"]= EGR_egr\n",
    "                                                each_wk_scheme_egr[wk_idx][\"hop\"]= hop_egr\n",
    "                                                each_wk_scheme_egr[wk_idx][\"EGRsquare\"]= EGRSQUARE_egr\n",
    "                                                each_wk_scheme_egr[wk_idx][\"Optimal\"]= optimal_egr\n",
    "                                            except:\n",
    "                                                each_wk_scheme_egr[wk_idx] = {}\n",
    "                                                each_wk_scheme_egr[wk_idx][\"EGR\"]= EGR_egr\n",
    "                                                each_wk_scheme_egr[wk_idx][\"hop\"]= hop_egr\n",
    "                                                each_wk_scheme_egr[wk_idx][\"EGRsquare\"]= EGRSQUARE_egr\n",
    "                                                each_wk_scheme_egr[wk_idx][\"Optimal\"]= optimal_egr\n",
    "                                    except:\n",
    "                                        EGR_egr = game.evaluate(wk_idx,network,solver,\"EGR\",[])\n",
    "                                        hop_egr = game.evaluate(wk_idx,network,solver,\"hop\",[])\n",
    "                                        EGRSQUARE_egr = game.evaluate(wk_idx,network,solver,\"EGRsquare\",[])\n",
    "                                        optimal_egr = game.evaluate(wk_idx,network,solver,\"Optimal\",[])\n",
    "                                        try:\n",
    "                                            each_wk_scheme_egr[wk_idx][\"EGR\"]= EGR_egr\n",
    "                                            each_wk_scheme_egr[wk_idx][\"hop\"]= hop_egr\n",
    "                                            each_wk_scheme_egr[wk_idx][\"EGRsquare\"]= EGRSQUARE_egr\n",
    "                                            each_wk_scheme_egr[wk_idx][\"Optimal\"]= optimal_egr\n",
    "                                        except:\n",
    "                                            each_wk_scheme_egr[wk_idx] = {}\n",
    "                                            each_wk_scheme_egr[wk_idx][\"EGR\"]= EGR_egr\n",
    "                                            each_wk_scheme_egr[wk_idx][\"hop\"]= hop_egr\n",
    "                                            each_wk_scheme_egr[wk_idx][\"EGRsquare\"]= EGRSQUARE_egr\n",
    "                                            each_wk_scheme_egr[wk_idx][\"Optimal\"]= optimal_egr\n",
    "                                    toplogy_wk_epoch_scheme_result = config.testing_results\n",
    "                                    rl_egr= sim(config,model,network,solver, game,wk_idx)\n",
    "                                    \n",
    "                                    if rl_egr >optimal_egr:\n",
    "                                        \n",
    "                                        import pdb\n",
    "                                        pdb.set_trace()\n",
    "                                    \n",
    "                                    with open(toplogy_wk_epoch_scheme_result, 'a') as newFile:                                \n",
    "                                        newFileWriter = csv.writer(newFile)\n",
    "                                        newFileWriter.writerow([config.topology_file,wk_idx,network.num_of_paths,\n",
    "                                        \"optimal\",optimal_egr,\n",
    "                                        \"RL\",rl_egr,\n",
    "                                        \"EGR\",EGR_egr,\n",
    "                                        \"hop\",hop_egr,\n",
    "                                        \"EGRsquare\",EGRSQUARE_egr,current_chckpoint,\n",
    "                                                            config.initial_learning_rate,\n",
    "                                                               config.learning_rate_decay_rate,\n",
    "                                                               config.moving_average_decay,\n",
    "                                                               config.entropy_weight,config.optimizer])\n",
    "                                    print(\"epoch #\",current_chckpoint,\"# paths\",network.num_of_paths,\"wk_idx\",wk_idx,\n",
    "                                                \"optimal\",optimal_egr,\n",
    "                                                \"RL\",rl_egr,\n",
    "                                                \"EGR\",EGR_egr,\n",
    "                                                \"hop\",hop_egr,\n",
    "                                                \"EGRsquare\",EGRSQUARE_egr)\n",
    "                                    try:\n",
    "                                        each_wk_idx_optimal[wk_idx].append(optimal_egr)\n",
    "                                    except:\n",
    "                                        each_wk_idx_optimal[wk_idx]=[optimal_egr]\n",
    "                                        \n",
    "                                    for wk_idx,optimal_values in each_wk_idx_optimal.items():\n",
    "                                        if int(sum(optimal_values)/len(optimal_values))!=int(optimal_values[0]):\n",
    "                                            print(\"ERROR!!!\", sum(optimal_values)/len(optimal_values),optimal_values[0])\n",
    "                                            pdb.set_trace()\n",
    "                            else:\n",
    "                                print(\"last %s current %s\"%(last_chckpoint,current_chckpoint))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ba0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3b31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
